import pinecone
import streamlit as st

from pages.lib.openai_call import get_embedding, get_chat_openai
from pages.lib.prompts import GENERATE_SELF_INTRODUCTION_PROMPT

st.set_page_config(
    page_title="Hello",
    page_icon="ğŸ‘‹",
)

question = st.radio(
    "ë‹µë³€í•˜ê³ ì í•˜ëŠ” ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
    ("ì§€ì› ë™ê¸°", "ì§ë¬´ ê´€ì‹¬ ê³„ê¸°", "íšŒì‚¬ ê²½ë ¥", "í”„ë¡œì íŠ¸ ê²½í—˜", "ì„±ê²©ì˜ ì¥ë‹¨ì ", "ì–´ë ¤ì›€ ê·¹ë³µ ê³¼ì •", "ë¬¸ì œ í•´ê²° ê²½í—˜"),
)

user_answer = st.text_area(
    label=question, placeholder=f"{question}ì— ëŒ€í•œ ìì‹ ì˜ ê²½í—˜ì„ ê°„ë‹¨í•˜ê²Œ ì†Œê°œí•´ì£¼ì„¸ìš”.", height=400
)

if st.button("ìƒì„±í•˜ê¸°!"):
    pinecone.init(api_key=st.secrets["PINECONE_API_KEY"], environment="gcp-starter")
    index = pinecone.Index("resumai-self-introduction-index")

    query_embedding = get_embedding(user_answer)

    retrieved_data = index.query(vector=query_embedding, top_k=5, include_metadata=True)

    data = retrieved_data["matches"]
    print(data)
    data_1_question = data[0]["metadata"]["question"]
    data_1_answer = data[0]["metadata"]["answer"]

    data_2_question = data[1]["metadata"]["question"]
    data_2_answer = data[1]["metadata"]["answer"]

    data_3_question = data[2]["metadata"]["question"]
    data_3_answer = data[2]["metadata"]["answer"]

    examples = (
        f"Question: {data_1_question}, \n Answer: {data_1_answer}, \n\n "
        f"Question: {data_2_question}, \n Answer: {data_2_answer}, \n\n "
        f"Question: {data_3_question}, \n Answer: {data_3_answer}"
    )

    print(examples)

    prompt = GENERATE_SELF_INTRODUCTION_PROMPT.format(
        examples=examples, question=question, context=user_answer
    )
    print(prompt)
    answer = get_chat_openai(prompt)

    with st.spinner("ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        if answer:
            st.success("ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤..")

    print(answer)

    st.write(answer)
